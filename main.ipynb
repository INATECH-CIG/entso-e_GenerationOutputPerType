{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# entso e Actual Generation per Type data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook we importing the entso e Actual Generation per Type data from OPSD data processing\n",
    "and correcting the hourly data with reported values from eurostat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ENTSO-E Transparency Platform, Actual Generation per Type Available online: https://transparency.entsoe.eu/generation/r2/actualGenerationPerProductionType/show (accessed on Oct 02, 2020).\n",
    " - Proccesed with OPSD time series scrips\n",
    " \n",
    "2. Energy Balances in the MS Excel file format (2020 edition) eurostat https://ec.europa.eu/eurostat/de/web/energy/data/energy-balances (accessed on Oct 02, 2020).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "\n",
    "#Helpers\n",
    "import os\n",
    "#import pycountry\n",
    "import glob\n",
    "from datetime import datetime, date, timedelta, time\n",
    "\n",
    "\n",
    "#Ploting\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = [15, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set data directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input, processed and output folders if they don't exist. If the paths are relative, the correspoding folders will be created inside the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory_path = os.path.join('input')\n",
    "processed_directory_path = 'processed'\n",
    "output_directory_path = os.path.join('output')\n",
    "\n",
    "sources_yaml_path = os.path.join('input', 'sources.yml')\n",
    "\n",
    "os.makedirs(input_directory_path, exist_ok=True)\n",
    "os.makedirs(processed_directory_path, exist_ok=True)\n",
    "os.makedirs(output_directory_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functionsÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function timeseries_opsd\n",
    "\n",
    "def load_timeseries_opsd(years=None, fn=None, countries=None, source=\"ENTSOE_transparency\"):\n",
    "    \"\"\"\n",
    "    Read data from OPSD time-series package own modification.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    years : None or slice()\n",
    "        Years for which to read load data (defaults to\n",
    "        slice(\"2018\",\"2019\"))\n",
    "        \n",
    "    fn : file name or url location (file format .csv)\n",
    "    \n",
    "    countries : Countries for which to read load data.\n",
    "        \n",
    "    source : \"ENTSOE_transparency\" or \"ENTSOE_power_statistics\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    load : pd.DataFrame\n",
    "        Load time-series with UTC timestamps x ISO-2 countries\n",
    "    \"\"\"\n",
    "\n",
    "     \n",
    "    if source == 'ENTSOE_transparency':\n",
    "        generation = (pd.read_csv(fn, index_col=[0], header=[0, 1, 2, 3, 4, 5], parse_dates=True)\n",
    "                    .dropna(how=\"all\", axis=0))\n",
    "        \n",
    "    else:\n",
    "        raise NotImplementedError(f\"Data for source `{source}` not available.\")\n",
    "    \n",
    "    \n",
    "    #generation = generation.rename(columns={'GB_UKM' : 'GB'}).filter(items=countries)\n",
    "       \n",
    "    \n",
    "    return generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_eurostat_energy_balance_sheets(path):\n",
    "    \"\"\"\n",
    "    Load and standardize the raw eurostat energy balance sheet files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : Path to data directory\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # combining path and .xlsb data\n",
    "    \n",
    "    filenames = sorted(glob.glob(path + \"/*.xlsb\"))\n",
    "    \n",
    "    # import xlsb files\n",
    "    # using pd.concat function as import function to append data to dataframe\n",
    "    # encoding: \"utf-16\" see entso-e documentation\n",
    "    # colum selection is possible by using \"usecols=['DateTime','ResolutionCode','AreaCode','AreaTypeCode','GenerationUnitEIC',...]\" \n",
    "    \n",
    "    entsoe_pp_timeseries = pd.concat((pd.read_csv(f, sep='\\t', encoding='utf-16', index_col = 3) for f in filenames))\n",
    "    \n",
    "    entsoe_pp_timeseries.drop(columns=[\"Year\",\"Month\",\"Day\"], inplace=True)\n",
    "    \n",
    "    entsoe_pp_timeseries.index = pd.to_datetime(entsoe_pp_timeseries.index)\n",
    "\n",
    "    #set generation and consumtion as absolut value (assuming that the negative entries are incorrect)\n",
    "    entsoe_pp_timeseries['ActualGenerationOutput'] = entsoe_pp_timeseries.ActualGenerationOutput.abs()\n",
    "    \n",
    "    entsoe_pp_timeseries['ActualConsumption'] = entsoe_pp_timeseries.ActualConsumption.abs()\n",
    "\n",
    "    return entsoe_pp_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_ProductionTypeName (entsoe_timeseries):\n",
    "    return entsoe_timeseries.ProductionTypeName.replace(\n",
    "                                {'Fossil Hard coal': 'Hard Coal',\n",
    "                                 'Fossil Brown coal/Lignite':'Lignite',\n",
    "                                 'Fossil Gas': 'Gas',\n",
    "                                 'Fossil Oil' : 'Other fossil',\n",
    "                                 'Fossil Coal-derived gas': 'Other fossil',\n",
    "                                 'Fossil Peat': 'Other fossil',\n",
    "                                 'Fossil Oil Shale' : 'Other fossil',\n",
    "                                 'Other' : 'Other fossil',\n",
    "                                 '.*Hydro.*': 'Hydro',\n",
    "                                 '.*Oil.*': 'Oil'\n",
    "                                 }, regex = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set filter parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    conventional:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# Change the production type names\n",
    "new_ProductionTypeName = False\n",
    "\n",
    "\n",
    "renewables:\n",
    "            Solar: solar\n",
    "            Wind Onshore: wind_onshore\n",
    "            Wind Offshore: wind_offshore\n",
    "            Biomass: biomass\n",
    "            Other renewable: other_renewable\n",
    "        conventional:\n",
    "            Fossil Hard coal: hard_coal \n",
    "            Fossil Brown coal/Lignite: lignite \n",
    "            Fossil Gas: gas \n",
    "            Fossil Oil: other_fossil\n",
    "            Fossil Coal-derived gas: other_fossil\n",
    "            Fossil Peat: other_fossil\n",
    "            Fossil Oil Shale: other_fossil\n",
    "            Other: other_fossil\n",
    "            Hydro Pumped Storage: hydro\n",
    "            Hydro Run-of-river and poundage: hydro\n",
    "            Hydro Water Reservoir: hydro\n",
    "            Fossil Oil: oil\n",
    "            Fossil Oil shale: oil \n",
    "\n",
    "\n",
    "#old                        : new\n",
    "#------------------------------------------------\n",
    "#'Fossil Hard coal'         : 'Hard Coal',\n",
    "#'Fossil Brown coal/Lignite': 'Lignite',\n",
    "#'Fossil Gas'               : 'Gas',\n",
    "#'Fossil Oil'               : 'Other fossil',\n",
    "#'Fossil Coal-derived gas'  : 'Other fossil',\n",
    "#'Fossil Peat'              : 'Other fossil',\n",
    "#'Fossil Oil Shale'         : 'Other fossil',\n",
    "#'Other'                    : 'Other fossil',\n",
    "#'.*Hydro.*'                : 'Hydro',\n",
    "#'.*Oil.*'                  : 'Oil'\n",
    "\n",
    "# dataset period\n",
    "start = '2019-01-01'\n",
    "end = '2020-01-01'\n",
    "closed='left' # end is not included \n",
    "\n",
    "# test dataet about gaps, timedate and duplicates\n",
    "test_dataset = False\n",
    "\n",
    "# countries to analyze\n",
    "#countries = ['AT', 'BE', 'BG', 'CH', 'CZ', 'DE', 'DK', 'EE', 'ES', 'FI', 'FR', 'GB', 'GR', 'HR', 'HU', 'IE', 'IT', 'LT', 'LU', 'LV', 'ME', 'NL', 'NO', 'PL', 'PT', 'RO', 'RS', 'SE', 'SI', 'SK']\n",
    "\n",
    "#'AL', \n",
    "#missing in the data 'BA', 'MK'\n",
    "\n",
    "#Dic to convert between alpha 3 and alpha 2\n",
    "countries_dic = {}\n",
    "for country in pycountry.countries:\n",
    "    countries_dic[country.alpha_3] = country.alpha_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Freddy\\.conda\\envs\\Lecture\\lib\\site-packages\\ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "with open(sources_yaml_path, 'r', encoding='UTF-8') as f:\n",
    "    sources = yaml.load(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anthracite': 'hard_coal',\n",
       " 'Coking coal': 'hard_coal',\n",
       " 'Other bituminous coal': 'hard_coal',\n",
       " 'Sub-bituminous coal': 'hard_coal',\n",
       " 'Lignite': 'lignite',\n",
       " 'Patent fuel': 'other_fossil',\n",
       " 'Coke oven coke': 'hard_coal',\n",
       " 'Gas coke': 'hard_coal',\n",
       " 'Coal tar': 'hard_coal',\n",
       " 'Brown coal briquettes': 'lignite',\n",
       " 'Gas works gas': 'gas',\n",
       " 'Coke oven gas': 'gas',\n",
       " 'Blast furnace gas': 'gas',\n",
       " 'Other recovered gases': 'gas',\n",
       " 'Peat': 'other_fossil',\n",
       " 'Peat products': 'other_fossil',\n",
       " 'Oil shale and oil sands': 'oil',\n",
       " 'Crude oil': 'oil',\n",
       " 'Natural gas liquids': 'oil',\n",
       " 'Refinery feedstocks': 'other_fossil',\n",
       " 'Other hydrocarbons': 'other_fossil',\n",
       " 'Refinery gas': 'other_fossil',\n",
       " 'Ethane': 'other_fossil',\n",
       " 'Liquefied petroleum gases': 'other_fossil',\n",
       " 'Motor gasoline (excluding biofuel portion)': 'other_fossil',\n",
       " 'Aviation gasoline': 'other_fossil',\n",
       " 'Gasoline-type jet fuel': 'other_fossil',\n",
       " 'Other kerosene': 'other_fossil',\n",
       " 'Naphtha': 'other_fossil',\n",
       " 'Fuel oil': 'oil',\n",
       " 'White spirit and special boiling point industrial spirits': 'other_fossil',\n",
       " 'Lubricants': 'other_fossil',\n",
       " 'Bitumen': None,\n",
       " 'Petroleum coke': 'other_fossil',\n",
       " 'Paraffin waxes': 'other_fossil',\n",
       " 'Other oil products': 'oil',\n",
       " 'Natural gas': 'gas',\n",
       " 'Hydro': 'hydro',\n",
       " 'Tide, wave, ocean': 'marine',\n",
       " 'Wind': 'wind',\n",
       " 'Solar photovoltaic': 'solar',\n",
       " 'Solar thermal': 'solar',\n",
       " 'Geothermal': 'geothermal',\n",
       " 'Primary solid biofuels': 'other_renewable',\n",
       " 'Charcoal': 'other_renewable',\n",
       " 'Biogases': 'biomass',\n",
       " 'Renewable municipal waste': 'other_renewable',\n",
       " 'Pure biogasoline': 'other_renewable',\n",
       " 'Blended biogasoline': 'other_renewable',\n",
       " 'Pure biodiesels': 'other_renewable',\n",
       " 'Blended biodiesels': 'other_renewable',\n",
       " 'Pure bio jet kerosene': 'other_renewable',\n",
       " 'Blended bio jet kerosene': 'other_renewable',\n",
       " 'Other liquid biofuels': 'other_renewable',\n",
       " 'Ambient heat (heat pumps)': 'other_renewable',\n",
       " 'Industrial waste (non-renewable)': 'waste',\n",
       " 'Non-renewable municipal waste': 'waste',\n",
       " 'Nuclear heat': 'nuclear'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources['eurostat energy balances']['Energy Balances in the MS Excel file format']['variable_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2018','2017','2016','2015']\n",
    "\n",
    "df= pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "    \n",
    "    df[year] = pd.read_excel(io=input_directory_path + '\\DE-Energy-balance-sheets-June-2020-edition.xlsb', sheet_name=year, engine='pyxlsb', header=135, skipfooter=10, usecols=sources['eurostat energy balances']['Energy Balances in the MS Excel file format']['variable_type'], na_values='Z').iloc[1:3].sum()\n",
    "\n",
    "# rename columns\n",
    "df.rename(sources['eurostat energy balances']['Energy Balances in the MS Excel file format']['variable_type'], inplace=True)\n",
    "\n",
    "\n",
    "#convert to MWh\n",
    "df = df * 11630"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index\n",
    "\n",
    "df = df.groupby(df.index).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2018</th>\n",
       "      <th>2017</th>\n",
       "      <th>2016</th>\n",
       "      <th>2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biomass</th>\n",
       "      <td>33.217001</td>\n",
       "      <td>33.668001</td>\n",
       "      <td>33.509996</td>\n",
       "      <td>32.891001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gas</th>\n",
       "      <td>56.370994</td>\n",
       "      <td>60.202997</td>\n",
       "      <td>56.925000</td>\n",
       "      <td>39.626003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geothermal</th>\n",
       "      <td>0.177997</td>\n",
       "      <td>0.162994</td>\n",
       "      <td>0.174997</td>\n",
       "      <td>0.133001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_coal</th>\n",
       "      <td>79.335999</td>\n",
       "      <td>89.461007</td>\n",
       "      <td>108.832993</td>\n",
       "      <td>116.803009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hydro</th>\n",
       "      <td>24.057004</td>\n",
       "      <td>25.983002</td>\n",
       "      <td>25.957997</td>\n",
       "      <td>24.739999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lignite</th>\n",
       "      <td>142.164004</td>\n",
       "      <td>144.958995</td>\n",
       "      <td>146.187995</td>\n",
       "      <td>151.143003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marine</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nuclear</th>\n",
       "      <td>76.005004</td>\n",
       "      <td>76.324003</td>\n",
       "      <td>84.633999</td>\n",
       "      <td>91.785995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oil</th>\n",
       "      <td>0.354006</td>\n",
       "      <td>0.476004</td>\n",
       "      <td>0.493007</td>\n",
       "      <td>0.892998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_fossil</th>\n",
       "      <td>0.022004</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.017003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_renewable</th>\n",
       "      <td>13.057001</td>\n",
       "      <td>12.401999</td>\n",
       "      <td>12.509996</td>\n",
       "      <td>12.690005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solar</th>\n",
       "      <td>45.783995</td>\n",
       "      <td>39.400998</td>\n",
       "      <td>38.097996</td>\n",
       "      <td>38.726004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waste</th>\n",
       "      <td>6.554994</td>\n",
       "      <td>6.759996</td>\n",
       "      <td>6.843011</td>\n",
       "      <td>6.563995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind</th>\n",
       "      <td>109.950997</td>\n",
       "      <td>105.692998</td>\n",
       "      <td>79.924000</td>\n",
       "      <td>80.623998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       2018        2017        2016        2015\n",
       "biomass           33.217001   33.668001   33.509996   32.891001\n",
       "gas               56.370994   60.202997   56.925000   39.626003\n",
       "geothermal         0.177997    0.162994    0.174997    0.133001\n",
       "hard_coal         79.335999   89.461007  108.832993  116.803009\n",
       "hydro             24.057004   25.983002   25.957997   24.739999\n",
       "lignite          142.164004  144.958995  146.187995  151.143003\n",
       "marine             0.000000    0.000000    0.000000    0.000000\n",
       "nuclear           76.005004   76.324003   84.633999   91.785995\n",
       "oil                0.354006    0.476004    0.493007    0.892998\n",
       "other_fossil       0.022004    0.007001    0.003001    0.017003\n",
       "other_renewable   13.057001   12.401999   12.509996   12.690005\n",
       "solar             45.783995   39.400998   38.097996   38.726004\n",
       "waste              6.554994    6.759996    6.843011    6.563995\n",
       "wind             109.950997  105.692998   79.924000   80.623998"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df/1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.import_module('pyxlsb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and filter dataÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and standardize data\n",
    "\n",
    "entsoe_gen_type = load_timeseries_opsd(years=None, fn=input_directory_path + '/time_series_60min_multiindex.csv', countries=None, source=\"ENTSOE_transparency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE = entsoe_gen_type['DE']\n",
    "DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entsoe_gen_type[('DE','gas')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = date(2018, 1, 1)\n",
    "end = date(2018, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE = DE.loc[start:end, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {'ResolutionCode': 'resolution',\n",
    "            'areacode': 'areacode',\n",
    "            'AreaTypeCode': 'AreaTypeCode',\n",
    "            'AreaName': 'region',\n",
    "            'MapCode': 'mapcode',\n",
    "            'ProductionType': 'variable',\n",
    "            'ActualGenerationOutput': 'generation_actual',\n",
    "            'ActualConsumption': 'consumption_actual',\n",
    "            'UpdateTime': 'updatetime'}\n",
    "\n",
    "entsoe_gen_type.rename(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entsoe_gen_type.drop(columns=['areacode','AreaTypeCode','mapcode','consumption_actual','updatetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entsoe_gen_type.dropna(subset=['generation_actual'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "res = '15'\n",
    "df = (entsoe_gen_type.loc[entsoe_gen_type['resolution'] == 'PT' + res + 'M', :]\n",
    "         .copy().sort_index(axis='columns'))\n",
    "df.drop(columns=['resolution'], inplace=True)\n",
    "\n",
    "stacked = ['region',  'variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(stacked, append=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.duplicated(keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.index.duplicated(keep=\"last\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.unstack(stacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, (df > 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['region', 'variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reorder_levels(headers, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for res in ['15', '30', '60']:\n",
    "    df = (entsoe_gen_type.loc[entsoe_gen_type['resolution'] == 'PT' + res + 'M', :]\n",
    "         .copy().sort_index(axis='columns'))\n",
    "    df.drop(columns=['resolution'], inplace=True)\n",
    "\n",
    "    # juggle the index and columns\n",
    "    df.set_index(stacked, append=True, inplace=True)\n",
    "    # at this point, only the values we are intereseted in are are left as\n",
    "    # columns\n",
    "    df.columns.rename(unstacked, inplace=True)\n",
    "    df = df.unstack(stacked)\n",
    "    \n",
    "    # keep only columns that have at least some nonzero values\n",
    "    df = df.loc[:, (df > 0).any(axis=0)]\n",
    "    \n",
    "    # add source, url and unit to the column names.\n",
    "    # Note: pd.concat inserts new MultiIndex values infront of the old ones\n",
    "    df = pd.concat([df],\n",
    "                   keys=[tuple(append_headers.values())],\n",
    "                   names=append_headers.keys(),\n",
    "                   axis='columns')\n",
    "    \n",
    "    # reorder and sort columns\n",
    "    df = df.reorder_levels(headers, axis=1)\n",
    "    \n",
    "    dfs[res + 'min'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entsoe_gen_type.rename(columns={Date})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # keep only entries for selected geographic entities as specified in\n",
    "    # areas.csv\n",
    "    area_filter = areas['primary AreaName ENTSO-E'].dropna()\n",
    "    df_raw = df_raw.loc[df_raw['region'].isin(area_filter)]\n",
    "    \n",
    "        #set generation and consumtion as absolut value (assuming that the negative entries are incorrect)\n",
    "    #entsoe_pp_timeseries['ActualGenerationOutput'] = entsoe_pp_timeseries.ActualGenerationOutput.abs()\n",
    "    \n",
    "    #entsoe_pp_timeseries['ActualConsumption'] = entsoe_pp_timeseries.ActualConsumption.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the availbe columns\n",
    "\n",
    "entsoe_gen_type.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entsoe_gen_type[.AreaName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entsoe_gen_type[entsoe_gen_type.AreaName == 'NO2 BZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entsoe_gen_type.MapCode.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the availbe 'ProductionTypeName'\n",
    "\n",
    "entsoe_gen_type.ProductionType.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the availbe countries\n",
    "\n",
    "entsoe_gen_type.MapCode.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace DE_* names with DE (DE is represend as four areas)\n",
    "\n",
    "entsoe_gen_unit.MapCode.replace({'.*DE.*' : 'DE'}, regex = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new names for production types\n",
    "\n",
    "if new_ProductionTypeName:\n",
    "    entsoe_gen_unit = change_ProductionTypeName(entsoe_gen_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which resolutions do exist in the data?\n",
    "\n",
    "entsoe_gen_unit.ResolutionCode.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many generators in the data\n",
    "\n",
    "len(entsoe_gen_unit.GenerationUnitEIC.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_dataset:\n",
    "    for i in entsoe_gen_unit.GenerationUnitEIC.unique():\n",
    "        unit_gen = entsoe_gen_unit.query(\"GenerationUnitEIC == @i\")\n",
    "\n",
    "        # test if different resolution codes exist for one power plant\n",
    "        if len(unit_gen.ResolutionCode.unique()) >= 2:\n",
    "            print('The data for generator ' + unit_gen.GenerationUnitEIC.iloc[0] + ' contains different time resolutions')\n",
    "            # for 2018 all data OK\n",
    "            # for 2019 all data OK\n",
    "        \n",
    "        if unit_gen.index.has_duplicates:\n",
    "            #print('The data for generator ' + unit_gen.GenerationUnitEIC.iloc[0] + ' contains duplicates in the index')\n",
    "            #many duplicates in 2019!\n",
    "            count = unit_gen.index.duplicated(keep='first').sum()\n",
    "            if count > 3:\n",
    "                print('The data for generator ' + unit_gen.GenerationUnitEIC.iloc[0] + ' contains more than 3 duplicates in the index')\n",
    "                #many duplicates with more than 3 duplicates in 2019!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling all generation data to hourly generation data per unit and store the data in a new dataframe 'gen_data'. Specific genertor unit data stored in 'unit_data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set timeframe\n",
    "t_index = pd.date_range(start=start, end=end, freq='60Min', closed=closed)\n",
    "\n",
    "# dataframe for generation data\n",
    "gen_data = pd.DataFrame(index=t_index)\n",
    "\n",
    "# dataframe for powerplant information\n",
    "unit_data = pd.DataFrame()\n",
    "\n",
    "\n",
    "# slicing over all generator units\n",
    "# takes some time\n",
    "for i in entsoe_gen_unit.GenerationUnitEIC.unique():\n",
    "    unit_gen = entsoe_gen_unit.query(\"GenerationUnitEIC == @i\").copy()\n",
    "    duplicate_count = 0\n",
    "    unit_gen['duplicate_count'] = duplicate_count\n",
    "    # test if different resolution codes exist for one power plant\n",
    "    if len(unit_gen.ResolutionCode.unique()) >= 2:\n",
    "        print('The data for generator ' + unit_gen.GenerationUnitEIC.iloc[0] + ' contains different time resolutions')\n",
    "        # for 2018 all data OK\n",
    "        # for 2019 all data OK\n",
    "    \n",
    "    # check if duplicates exist in index (datetime) for the power plant and drop them\n",
    "    if unit_gen.index.has_duplicates:\n",
    "        #many duplicates in 2019!\n",
    "        \n",
    "        duplicate_count = unit_gen.index.duplicated(keep='first').sum()\n",
    "        \n",
    "        #drop all duplicates and only keep the first entry \n",
    "        unit_gen = unit_gen[~unit_gen.index.duplicated(keep='first')]\n",
    "        unit_gen['duplicate_count'] = duplicate_count\n",
    "    \n",
    "    #resampling the data to 1h and store it in \"gen_data\"\n",
    "    gen_data[i] = resampling(pp_gen=unit_gen, start=start, end=end, resolution='60Min')['ActualGenerationOutput']\n",
    "   \n",
    "    #store power plant info in unit_data\n",
    "    unit_data = unit_data.append((unit_gen.set_index('GenerationUnitEIC')[['AreaCode', 'AreaTypeCode', 'AreaName', 'MapCode', 'PowerSystemResourceName', 'ProductionTypeName','InstalledGenCapacity','duplicate_count']].iloc[0]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the \"unit_data\" dataframe in combination with the .groupby() function the data can be easily grouped and analyzed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hourly data per county and technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will result in a multi index dataframe\n",
    "data_country_tech_hourly = gen_data.groupby([unit_data.MapCode, unit_data.ProductionTypeName], axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_country_tech_hourly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly data per county and technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate month as a grouper\n",
    "data_country_tech_hourly['Month'] = pd.DatetimeIndex(data_country_tech_hourly.index).month\n",
    "\n",
    "#will result in a multi index dataframe\n",
    "data_country_tech_monthly = data_country_tech_hourly.groupby(data_country_tech_hourly.Month, axis=0).sum()\n",
    "\n",
    "#drop the grouper from resulting dataframe\n",
    "data_country_tech_monthly.drop(['Month'],axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_country_tech_monthly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yearly data per county and technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the data from multiindex dataframe and convert multiindex into columns and rows\n",
    "data_country_tech_yearly = data_country_tech_hourly.sum().unstack(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_country_tech_yearly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Germany as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE = data_country_tech_hourly['DE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# production per technology in GWh\n",
    "DE.sum()/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(data=DE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Export data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data as .csv files. All files are saved in the output directory of this notebook. Take some time (2 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourly data\n",
    "data_country_tech_hourly.to_csv(output_directory_path + '/data_country_tech_hourly.csv')\n",
    "\n",
    "# monthly data\n",
    "data_country_tech_monthly.to_csv(output_directory_path + '/data_country_tech_monthly.csv')\n",
    "\n",
    "# yearly data\n",
    "data_country_tech_yearly.to_csv(output_directory_path + '/data_country_tech_yearly.csv')\n",
    "\n",
    "# power plant information\n",
    "unit_data.to_csv(output_directory_path + '/unit_data.csv')\n",
    "\n",
    "# hourly unit generation data\n",
    "gen_data.to_csv(output_directory_path + '/gen_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
